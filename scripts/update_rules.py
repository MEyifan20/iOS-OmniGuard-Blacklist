import os
import re
import datetime
import urllib.request

# ä¸Šæ¸¸ 217heidai è§„åˆ™åœ°å€
UPSTREAM_URL = "https://raw.githubusercontent.com/217heidai/adblockdns/main/rule/adblockdns.txt"

def get_upstream_rules():
    print(f"â³ æ­£åœ¨æ‹‰å–ä¸Šæ¸¸è§„åˆ™: {UPSTREAM_URL}")
    try:
        # ä¼ªè£…è¯·æ±‚å¤´ï¼Œé˜²æ­¢è¢« GitHub Raw æ‹’ç»
        req = urllib.request.Request(UPSTREAM_URL, headers={'User-Agent': 'Mozilla/5.0'})
        with urllib.request.urlopen(req, timeout=30) as response:
            content = response.read().decode('utf-8')
            # æå–æ‰€æœ‰è§„åˆ™ï¼Œè¿‡æ»¤æ‰æ³¨é‡Šå’Œç©ºè¡Œï¼Œæ”¾å…¥é›†åˆä¸­ä»¥ä¾› O(1) æé€ŸæŸ¥è¯¢
            rules = set([line.strip() for line in content.splitlines() if line.strip() and not line.startswith('!') and not line.startswith('#')])
            print(f"âœ… æˆåŠŸæ‹‰å–ä¸Šæ¸¸è§„åˆ™ï¼Œå…±è®¡ {len(rules)} æ¡æœ‰æ•ˆè§„åˆ™ã€‚")
            return rules
    except Exception as e:
        print(f"âŒ æ‹‰å–ä¸Šæ¸¸è§„åˆ™å¤±è´¥: {e}")
        return set()

def process_and_deduplicate(blacklist_path, upstream_rules):
    if not os.path.exists(blacklist_path):
        print(f"âš ï¸ æ‰¾ä¸åˆ°æ–‡ä»¶: {blacklist_path}")
        return

    with open(blacklist_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()

    new_lines = []
    removed_count = 0

    for line in lines:
        stripped_line = line.strip()
        
        # 1. ä¿ç•™å…ƒæ•°æ®ã€ç©ºè¡Œã€æ³¨é‡Š
        if not stripped_line or stripped_line.startswith('!') or stripped_line.startswith('['):
            new_lines.append(line)
            continue
        
        # 2. ä¿ç•™æ‰€æœ‰å¸¦æœ‰é«˜çº§ä¿®é¥°ç¬¦çš„â€œæˆ˜æœ¯çº§è§„åˆ™â€ (ä½ çš„å¿ƒè¡€)
        if '$important' in stripped_line or '##' in stripped_line or '#%#' in stripped_line or '@@' in stripped_line:
            new_lines.append(line)
            continue

        # 3. æ ¸å¿ƒå»é‡ï¼šå¦‚æœè¿™æ¡æ™®é€šè§„åˆ™åœ¨ä¸Šæ¸¸åº“ä¸­å·²ç»å­˜åœ¨ï¼Œåˆ™å‰”é™¤
        if stripped_line in upstream_rules:
            removed_count += 1
            print(f"ğŸ—‘ï¸ å‘ç°å†—ä½™å¹¶å‰”é™¤: {stripped_line}")
            continue
        
        # 4. å…¶ä»–æœ¬åœ°ç‹¬æœ‰çš„è§„åˆ™ï¼Œä¿ç•™
        new_lines.append(line)

    # å‡†å¤‡å†™å…¥æ–°çš„æ—¶é—´æˆ³ä¸ç‰ˆæœ¬å·
    tz = datetime.timezone(datetime.timedelta(hours=8))
    now = datetime.datetime.now(tz)
    version_str = now.strftime("%Y.%m.%d.%H")
    time_str = now.strftime("%Y-%m-%d %H:%M")

    final_content = "".join(new_lines)
    # ä½¿ç”¨æ­£åˆ™æ›¿æ¢æ–‡ä»¶å¤´çš„ç‰ˆæœ¬å’Œæ—¶é—´
    final_content = re.sub(r'! Version: .*', f'! Version: {version_str}', final_content)
    final_content = re.sub(r'! Updated: .*', f'! Updated: {time_str}', final_content)

    with open(blacklist_path, 'w', encoding='utf-8') as f:
        f.write(final_content)
    
    print(f"âœ… é»‘åå•å¤„ç†å®Œæˆï¼æœ¬æ¬¡å‰”é™¤äº† {removed_count} æ¡ä¸ä¸Šæ¸¸é‡å¤çš„è§„åˆ™ã€‚")
    print(f"âœ… é»‘åå•å·²æ›´æ–°è‡³ç‰ˆæœ¬: {version_str}")

def update_readme():
    readme_path = 'README.md'
    if not os.path.exists(readme_path):
        return
        
    tz = datetime.timezone(datetime.timedelta(hours=8))
    now = datetime.datetime.now(tz)
    version_str = now.strftime("%Y.%m.%d.%H")
    time_str = now.strftime("%Y-%m-%d %H:%M")

    with open(readme_path, 'r', encoding='utf-8') as f:
        readme_content = f.read()
    
    # æ›¿æ¢ README ä¸­çš„ç‰ˆæœ¬å’Œæ—¶é—´
    readme_content = re.sub(r'! Version: .*', f'! Version: {version_str}', readme_content)
    readme_content = re.sub(r'! Updated: .*', f'! Updated: {time_str}', readme_content)
    readme_content = re.sub(r'\*\*æœ€åä¿®æ”¹æ—¶é—´\*\*ï¼š.*', f'**æœ€åä¿®æ”¹æ—¶é—´**ï¼š{time_str} (GMT+8)', readme_content)

    with open(readme_path, 'w', encoding='utf-8') as f:
        f.write(readme_content)
    print(f"âœ… README.md åŒæ­¥æ›´æ–°å®Œæ¯•ã€‚")

if __name__ == '__main__':
    # 1. æŠ“å–ä¸Šæ¸¸
    upstream = get_upstream_rules()
    # 2. å»é‡å¹¶æ›´æ–°é»‘åå•
    process_and_deduplicate('iOS-OmniGuard-Blacklist.txt', upstream)
    # 3. æ›´æ–° README
    update_readme()
